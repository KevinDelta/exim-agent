{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory System Practice\n",
    "\n",
    "This notebook demonstrates the complete **three-tier memory system** implementation.\n",
    "\n",
    "## Memory Architecture\n",
    "\n",
    "The system implements:\n",
    "\n",
    "1. **Working Memory (WM)**: Recent conversation turns (in-memory, last N messages)\n",
    "2. **Episodic Memory (EM)**: Session-specific facts distilled from conversations\n",
    "3. **Semantic Memory (SM)**: Long-term knowledge from documents\n",
    "\n",
    "## Contents\n",
    "1. Setup and Initialization\n",
    "2. Working Memory (Session Management)\n",
    "3. Intent Classification and Entity Extraction\n",
    "4. Episodic Memory Operations\n",
    "5. Semantic Memory Retrieval\n",
    "6. Combined Memory Recall (EM + SM)\n",
    "7. LangGraph State Machine Flow\n",
    "8. Salience Tracking and Distillation\n",
    "9. End-to-End Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinknox/coding/acc-llamaindex/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-10-19 21:48:31.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.reranking_service.service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mRerankingService initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.evaluation_service.service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mEvaluationService initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mChatService initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.session_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mSessionManager initialized (max_sessions=100, ttl=30min)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mMemoryService initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.langchain_provider\u001b[0m:\u001b[36m_initialize_llm\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mInitializing LLM with provider: openai\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.openai_provider\u001b[0m:\u001b[36minitialize_llm\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mInitializing ChatOpenAI with model: gpt-5-nano-2025-08-07\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.openai_provider\u001b[0m:\u001b[36minitialize_llm\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mChatOpenAI initialized successfully\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mIntentClassifier initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mEntityExtractor initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.salience_tracker\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mSalienceTracker initialized (batch_size=50)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.conversation_summarizer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mConversationSummarizer initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.langchain_provider\u001b[0m:\u001b[36m_initialize_embeddings\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mInitializing embeddings with provider: openai\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.openai_provider\u001b[0m:\u001b[36minitialize_embeddings\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mInitializing OpenAIEmbeddings with model: text-embedding-3-small\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.llm_providers.openai_provider\u001b[0m:\u001b[36minitialize_embeddings\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mOpenAIEmbeddings initialized successfully\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.deduplication\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mFactDeduplicator initialized (threshold=0.92)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.promotion\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mMemoryPromoter initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.background_jobs\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mMemoryBackgroundJobs initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:31.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.metrics\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mMemoryMetrics initialized\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All memory system imports successful\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import memory system components\n",
    "from acc_llamaindex.config import config\n",
    "from acc_llamaindex.application.chat_service.session_manager import session_manager\n",
    "from acc_llamaindex.application.memory_service.intent_classifier import intent_classifier\n",
    "from acc_llamaindex.application.memory_service.entity_extractor import entity_extractor\n",
    "from acc_llamaindex.application.memory_service.service import memory_service\n",
    "from acc_llamaindex.application.memory_service.salience_tracker import salience_tracker\n",
    "from acc_llamaindex.application.memory_service.conversation_summarizer import conversation_summarizer\n",
    "from acc_llamaindex.application.chat_service.graph import get_memory_graph, MemoryState\n",
    "from acc_llamaindex.infrastructure.llm_providers.langchain_provider import get_llm, reset_llm\n",
    "from acc_llamaindex.infrastructure.db.chroma_client import chroma_client\n",
    "\n",
    "print(\"✓ All memory system imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working Memory (Session Management)\n",
    "\n",
    "Working Memory stores recent conversation turns in-memory with:\n",
    "- LRU eviction when max sessions reached\n",
    "- TTL-based cleanup of expired sessions\n",
    "- Thread-safe operations\n",
    "\n",
    "### Pattern 1: Create and Manage Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:32.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mInitializing ChromaDB at /Users/kevinknox/coding/acc-llamaindex/data/chroma_db\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:33.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mChromaDB client and embeddings initialized\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:33.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36minitialize\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mSemantic memory collection initialized: documents\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:33.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36m_initialize_episodic_memory\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mInitializing episodic memory collection: episodic_memory\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:33.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36m_initialize_episodic_memory\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEpisodic memory collection initialized successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory System Config:\n",
      "- WM Max Turns: 10\n",
      "- WM Max Sessions: 100\n",
      "- WM Session TTL: 30 minutes\n",
      "- EM Collection: episodic_memory\n",
      "- SM Collection: documents\n",
      "- EM K Default: 5\n",
      "- SM K Default: 10\n",
      "- Enable Memory System: True\n",
      "- Enable EM Distillation: True\n",
      "- Distill Every N Turns: 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize core services\n",
    "chroma_client.initialize()\n",
    "get_llm()\n",
    "\n",
    "print(f\"\\nMemory System Config:\")\n",
    "print(f\"- WM Max Turns: {config.wm_max_turns}\")\n",
    "print(f\"- WM Max Sessions: {config.wm_max_sessions}\")\n",
    "print(f\"- WM Session TTL: {config.wm_session_ttl_minutes} minutes\")\n",
    "print(f\"- EM Collection: {config.em_collection_name}\")\n",
    "print(f\"- SM Collection: {config.chroma_collection_name}\")  # SM uses main collection\n",
    "print(f\"- EM K Default: {config.em_k_default}\")\n",
    "print(f\"- SM K Default: {config.sm_k_default}\")\n",
    "print(f\"- Enable Memory System: {config.enable_memory_system}\")\n",
    "print(f\"- Enable EM Distillation: {config.enable_em_distillation}\")\n",
    "print(f\"- Distill Every N Turns: {config.em_distill_every_n_turns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:37.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.session_manager\u001b[0m:\u001b[36mcreate_session\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mCreated session demo-session-001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created session: demo-session-001\n",
      "Created at: 2025-10-19 21:48:37.192629\n",
      "Turn count: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a new session\n",
    "session_id = \"demo-session-001\"\n",
    "session = session_manager.create_session(session_id)\n",
    "\n",
    "print(f\"Created session: {session['session_id']}\")\n",
    "print(f\"Created at: {session['created_at']}\")\n",
    "print(f\"Turn count: {session['turn_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Add Conversation Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:39.334\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.session_manager\u001b[0m:\u001b[36madd_turn\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mAdded turn 1 to session demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:39.335\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.session_manager\u001b[0m:\u001b[36madd_turn\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mAdded turn 2 to session demo-session-001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 turns to session demo-session-001\n"
     ]
    }
   ],
   "source": [
    "# Add conversation turns\n",
    "session_manager.add_turn(\n",
    "    session_id=session_id,\n",
    "    user_message=\"What is the African Growth and Opportunity Act?\",\n",
    "    assistant_message=\"AGOA is a U.S. trade program providing preferential access to African countries.\",\n",
    "    metadata={\"intent\": \"compliance_query\", \"entities\": [{\"text\": \"AGOA\", \"type\": \"program\"}]}\n",
    ")\n",
    "\n",
    "session_manager.add_turn(\n",
    "    session_id=session_id,\n",
    "    user_message=\"Which countries are eligible?\",\n",
    "    assistant_message=\"Sub-Saharan African countries that meet eligibility criteria.\",\n",
    "    metadata={\"intent\": \"general\", \"entities\": []}\n",
    ")\n",
    "\n",
    "print(f\"Added 2 turns to session {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Retrieve Recent Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 2 recent turns:\n",
      "\n",
      "Turn 1:\n",
      "  User: What is the African Growth and Opportunity Act?\n",
      "  Assistant: AGOA is a U.S. trade program providing preferential access to African countries.\n",
      "  Metadata: {'intent': 'compliance_query', 'entities': [{'text': 'AGOA', 'type': 'program'}]}\n",
      "\n",
      "Turn 2:\n",
      "  User: Which countries are eligible?\n",
      "  Assistant: Sub-Saharan African countries that meet eligibility criteria.\n",
      "  Metadata: {'intent': 'general', 'entities': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get recent turns\n",
    "recent_turns = session_manager.get_recent_turns(session_id, n=2)\n",
    "\n",
    "print(f\"Retrieved {len(recent_turns)} recent turns:\\n\")\n",
    "for turn in recent_turns:\n",
    "    print(f\"Turn {turn['turn_number']}:\")\n",
    "    print(f\"  User: {turn['user_message']}\")\n",
    "    print(f\"  Assistant: {turn['assistant_message']}\")\n",
    "    print(f\"  Metadata: {turn['metadata']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intent Classification and Entity Extraction\n",
    "\n",
    "Intent classification helps route queries:\n",
    "- `quote_request`: Price quotes\n",
    "- `compliance_query`: Regulations\n",
    "- `shipment_tracking`: Tracking\n",
    "- `general`: General questions\n",
    "\n",
    "### Pattern 1: Classify User Intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:45.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mClassifying intent for query: What is the price for shipping 100 units to Lagos?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Classification Results:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:48.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mIntent classified: quote_request (confidence: 0.85)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:48.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mClassifying intent for query: What are the import regulations for textiles?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the price for shipping 100 units to Lagos?\n",
      "  Intent: quote_request (confidence: 0.85)\n",
      "  Reasoning: User asked for the price/quote for shipping 100 units to Lagos, which is a request for a shipping quote.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:50.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mIntent classified: compliance_query (confidence: 0.80)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:50.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mClassifying intent for query: Where is my shipment TRK-12345?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the import regulations for textiles?\n",
      "  Intent: compliance_query (confidence: 0.80)\n",
      "  Reasoning: User asked about import regulations for textiles, which relates to regulatory/compliance information (customs, documentation, standards).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:53.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mIntent classified: shipment_tracking (confidence: 0.92)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:48:53.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mClassifying intent for query: What is AGOA?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Where is my shipment TRK-12345?\n",
      "  Intent: shipment_tracking (confidence: 0.92)\n",
      "  Reasoning: User asks for the current location/status of a shipment using a tracking number TRK-12345, which is a tracking inquiry.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:55.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mIntent classified: compliance_query (confidence: 0.78)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is AGOA?\n",
      "  Intent: compliance_query (confidence: 0.78)\n",
      "  Reasoning: AGOA is a trade regulation/program (African Growth and Opportunity Act) relevant to shipments and compliance requirements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries with different intents\n",
    "test_queries = [\n",
    "    \"What is the price for shipping 100 units to Lagos?\",\n",
    "    \"What are the import regulations for textiles?\",\n",
    "    \"Where is my shipment TRK-12345?\",\n",
    "    \"What is AGOA?\"\n",
    "]\n",
    "\n",
    "print(\"Intent Classification Results:\\n\")\n",
    "for query in test_queries:\n",
    "    result = intent_classifier.classify(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"  Intent: {result['intent']} (confidence: {result['confidence']:.2f})\")\n",
    "    print(f\"  Reasoning: {result.get('reasoning', 'N/A')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:48:56.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36m_extract_with_llm\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mUsing LLM fallback for entity extraction: I need to ship 500 smartphones from China to Niger\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:05.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mExtracted 4 entities from query: I need to ship 500 smartphones from China to Niger\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:05.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m139\u001b[0m - \u001b[34m\u001b[1m  - incoterm: FOB (incoterm:fob)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:05.627\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m139\u001b[0m - \u001b[34m\u001b[1m  - commodity: smartphones (commodity:smartphones)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:05.627\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m139\u001b[0m - \u001b[34m\u001b[1m  - country: China (country:china)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:05.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m139\u001b[0m - \u001b[34m\u001b[1m  - country: Nigeria (country:nigeria)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I need to ship 500 smartphones from China to Nigeria using FOB Incoterms\n",
      "\n",
      "Extracted Entities:\n",
      "  - FOB (incoterm)\n",
      "  - smartphones (commodity)\n",
      "  - China (country)\n",
      "  - Nigeria (country)\n"
     ]
    }
   ],
   "source": [
    "# Extract entities from queries\n",
    "query = \"I need to ship 500 smartphones from China to Nigeria using FOB Incoterms\"\n",
    "entities = entity_extractor.extract(query)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Extracted Entities:\")\n",
    "for entity in entities:\n",
    "    print(f\"  - {entity['text']} ({entity['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Episodic Memory Operations\n",
    "\n",
    "Episodic Memory stores session-specific facts extracted from conversations.\n",
    "\n",
    "### Pattern 1: Add Facts to Episodic Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:10.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36mwrite_episodic\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mWrote 1 items to episodic memory\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:10.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36mwrite_episodic\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mWrote 1 items to episodic memory\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added EM fact 1: User is interested in exporting textiles to Nigeria\n",
      "Added EM fact 2: User prefers FOB Incoterms for shipments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:10.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.infrastructure.db.chroma_client\u001b[0m:\u001b[36mwrite_episodic\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mWrote 1 items to episodic memory\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added EM fact 3: User mentioned working with supplier in Lagos\n"
     ]
    }
   ],
   "source": [
    "# Add episodic facts manually (normally done via distillation)\n",
    "facts = [\n",
    "    \"User is interested in exporting textiles to Nigeria\",\n",
    "    \"User prefers FOB Incoterms for shipments\",\n",
    "    \"User mentioned working with supplier in Lagos\"\n",
    "]\n",
    "\n",
    "for i, fact in enumerate(facts, 1):\n",
    "    chroma_client.write_episodic(\n",
    "        texts=[fact],\n",
    "        metadatas=[{  # Must be a list of dicts\n",
    "            \"session_id\": session_id,\n",
    "            \"fact_id\": f\"fact-{i}\",\n",
    "            \"source\": \"manual_test\",\n",
    "            \"salience_score\": 0.7\n",
    "        }]\n",
    "    )\n",
    "    print(f\"Added EM fact {i}: {fact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Query Episodic Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:19.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 3 EM results for session demo-session-001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What shipping terms does the user prefer?\n",
      "\n",
      "Episodic Memory Results (3 found):\n",
      "\n",
      "Result 1:\n",
      "  Text: User prefers FOB Incoterms for shipments\n",
      "  Salience: 0.5000\n",
      "  Source: EM\n",
      "  Metadata: {'source': 'manual_test', 'salience_score': 0.7, 'fact_id': 'fact-2', 'session_id': 'demo-session-001'}\n",
      "\n",
      "Result 2:\n",
      "  Text: User prefers FOB Incoterms for shipments\n",
      "  Salience: 0.5000\n",
      "  Source: EM\n",
      "  Metadata: {'session_id': 'demo-session-001', 'fact_id': 'fact-2', 'source': 'manual_test', 'salience_score': 0.7}\n",
      "\n",
      "Result 3:\n",
      "  Text: User is interested in exporting textiles to Nigeria\n",
      "  Salience: 0.5000\n",
      "  Source: EM\n",
      "  Metadata: {'fact_id': 'fact-1', 'salience_score': 0.7, 'source': 'manual_test', 'session_id': 'demo-session-001'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query EM for session-specific context\n",
    "query = \"What shipping terms does the user prefer?\"\n",
    "\n",
    "em_results = memory_service._query_episodic(\n",
    "    session_id=session_id,\n",
    "    query=query,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Episodic Memory Results ({len(em_results)} found):\\n\")\n",
    "for i, result in enumerate(em_results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"  Text: {result['text']}\")\n",
    "    print(f\"  Salience: {result.get('salience', 0.0):.4f}\")\n",
    "    print(f\"  Source: {result.get('source', 'unknown')}\")\n",
    "    print(f\"  Metadata: {result.get('metadata', {})}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Memory Retrieval\n",
    "\n",
    "Semantic Memory contains long-term knowledge from documents.\n",
    "\n",
    "### Pattern 1: Query Semantic Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:26.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36mrecall\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mMemory recall: query=What are FOB Incoterms?, intent=general, session=any-session, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:27.347\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 0 EM results for session any-session\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:27.543\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_semantic\u001b[0m:\u001b[36m162\u001b[0m - \u001b[34m\u001b[1mRetrieved 5 SM results for intent=general, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:27.543\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_merge_results\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mMerged results: 0 EM + 5 SM = 5 (deduped)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are FOB Incoterms?\n",
      "\n",
      "Semantic Memory Results (5 found):\n",
      "\n",
      "Result 1:\n",
      "  Text: FAS - Free Alongside Ship\n",
      "“Free Alongside Ship” means that the seller delivers when the goods are placed alongside the vessel (e.g., on a\n",
      "quay or a barge) nominated by the buyer at the named port of s...\n",
      "  salience: 0.0000\n",
      "  Source: SM\n",
      "\n",
      "Result 2:\n",
      "  Text: If selling on FOB terms:\n",
      "You will only have to cover the costs to get the goods loaded on board the vessel ready for export – so you\n",
      "will cover the container trucking from your warehouse to the port p...\n",
      "  salience: 0.0000\n",
      "  Source: SM\n",
      "\n",
      "Result 3:\n",
      "  Text: Put simply, Incoterms® are the selling terms that the buyer and seller of goods both agrees to.  The Incoterm®\n",
      "clearly states which tasks, costs and risks are associated with the buyer and the seller....\n",
      "  salience: 0.0000\n",
      "  Source: SM\n",
      "\n",
      "Result 4:\n",
      "  Text: Buyer’s and Seller’s Own Transport\n",
      "Under Incoterms® 2010 it was assumed that all transport would be undertaken by a third party transport\n",
      "provider. Updates to Incoterms® 2020 allows for the provision ...\n",
      "  salience: 0.0000\n",
      "  Source: SM\n",
      "\n",
      "Result 5:\n",
      "  Text: they have been shipped, then you can use your CFR terms as security by not handing over the original Bills of\n",
      "Lading to the buyer until you received the balance payment. The buyer can only clear the g...\n",
      "  salience: 0.0000\n",
      "  Source: SM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query SM for document knowledge\n",
    "query = \"What are FOB Incoterms?\"\n",
    "\n",
    "sm_results = memory_service.recall(\n",
    "    query=query,\n",
    "    session_id=\"any-session\",\n",
    "    intent=\"general\",\n",
    "    entities=[{\"text\": \"FOB\", \"type\": \"incoterm\"}],\n",
    "    k_em=0,  # Only SM\n",
    "    k_sm=5\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Semantic Memory Results ({len(sm_results['sm_results'])} found):\\n\")\n",
    "for i, result in enumerate(sm_results['sm_results'], 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"  Text: {result['text'][:200]}...\")\n",
    "    print(f\"  salience: {result['salience']:.4f}\")\n",
    "    print(f\"  Source: {result.get('source', 'unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combined Memory Recall (EM + SM)\n",
    "\n",
    "The memory service intelligently combines episodic and semantic memory.\n",
    "\n",
    "### Pattern 1: Basic Combined Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:31.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36mrecall\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mMemory recall: query=What Incoterms should I use for my Nigeria shipmen, intent=general, session=demo-session-001, entities=2\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:31.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 3 EM results for session demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:31.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_semantic\u001b[0m:\u001b[36m162\u001b[0m - \u001b[34m\u001b[1mRetrieved 3 SM results for intent=general, entities=2\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:31.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_merge_results\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mMerged results: 3 EM + 3 SM = 5 (deduped)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What Incoterms should I use for my Nigeria shipment?\n",
      "\n",
      "Episodic Memory (3 results):\n",
      "  - User prefers FOB Incoterms for shipments\n",
      "  - User prefers FOB Incoterms for shipments\n",
      "  - User is interested in exporting textiles to Nigeria\n",
      "\n",
      "Semantic Memory (3 results):\n",
      "  - to, which may occur when it is being used to confirm complex commercial agreements.\n",
      "All parties must...\n",
      "  - Letter of Credit.\n",
      "Therefore provisions have been made to the Incoterms® 2020 to state that the buyer...\n",
      "  - Ensure that you make changes to any contracts and documents as necessary\n",
      "Ensure that you are stating...\n",
      "\n",
      "Combined & Reranked (5 results):\n",
      "  1. [EM] User prefers FOB Incoterms for shipments...\n",
      "  2. [EM] User is interested in exporting textiles to Nigeria...\n",
      "  3. [SM] to, which may occur when it is being used to confirm complex commercial agreemen...\n",
      "  4. [SM] Letter of Credit.\n",
      "Therefore provisions have been made to the Incoterms® 2020 to ...\n",
      "  5. [SM] Ensure that you make changes to any contracts and documents as necessary\n",
      "Ensure ...\n"
     ]
    }
   ],
   "source": [
    "# Combined EM + SM recall\n",
    "query = \"What Incoterms should I use for my Nigeria shipment?\"\n",
    "\n",
    "combined_results = memory_service.recall(\n",
    "    query=query,\n",
    "    session_id=session_id,\n",
    "    intent=\"general\",\n",
    "    entities=[{\"text\": \"Nigeria\", \"type\": \"location\"}, {\"text\": \"Incoterms\", \"type\": \"term\"}],\n",
    "    k_em=3,\n",
    "    k_sm=3\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Episodic Memory ({len(combined_results['em_results'])} results):\") \n",
    "for result in combined_results['em_results']:\n",
    "    print(f\"  - {result['text']}\")\n",
    "\n",
    "print(f\"\\nSemantic Memory ({len(combined_results['sm_results'])} results):\")\n",
    "for result in combined_results['sm_results']:\n",
    "    print(f\"  - {result['text'][:100]}...\")\n",
    "\n",
    "print(f\"\\nCombined & Reranked ({len(combined_results['combined_results'])} results):\")\n",
    "for i, result in enumerate(combined_results['combined_results'], 1):\n",
    "    source = result.get('source', 'unknown')\n",
    "    print(f\"  {i}. [{source}] {result['text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LangGraph State Machine Flow\n",
    "\n",
    "The memory graph orchestrates the entire memory flow.\n",
    "\n",
    "### Pattern 1: Execute Full Memory Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:38.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mcreate_memory_graph\u001b[0m:\u001b[36m343\u001b[0m - \u001b[1mMemory graph created successfully\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:38.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mload_working_memory\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mLoading working memory for session: demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:38.023\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mload_working_memory\u001b[0m:\u001b[36m67\u001b[0m - \u001b[34m\u001b[1mLoaded 2 turns from working memory\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:38.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mclassify_intent\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mClassifying intent for query: What Incoterms are best for shipping to Africa?...\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:38.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mClassifying intent for query: What Incoterms are best for shipping to Africa?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing memory graph...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 21:49:41.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.intent_classifier\u001b[0m:\u001b[36m_classify_cached\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mIntent classified: compliance_query (confidence: 0.62)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:41.511\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36m_extract_with_llm\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mUsing LLM fallback for entity extraction: What Incoterms are best for shipping to Africa?\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mExtracted 1 entities from query: What Incoterms are best for shipping to Africa?\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.360\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.entity_extractor\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m139\u001b[0m - \u001b[34m\u001b[1m  - incoterm: Incoterms (incoterm:incoterms)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mclassify_intent\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mIntent: compliance_query (confidence: 0.62), Entities: 1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mquery_episodic_memory\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mQuerying episodic memory for session: demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mquery_semantic_memory\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mQuerying semantic memory with intent: compliance_query\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36mrecall\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mMemory recall: query=What Incoterms are best for shipping to Africa?, intent=compliance_query, session=demo-session-001, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36mrecall\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mMemory recall: query=What Incoterms are best for shipping to Africa?, intent=compliance_query, session=demo-session-001, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.514\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 5 EM results for session demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.576\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 5 EM results for session demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.707\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_semantic\u001b[0m:\u001b[36m162\u001b[0m - \u001b[34m\u001b[1mRetrieved 0 SM results for intent=compliance_query, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.707\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_merge_results\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mMerged results: 5 EM + 0 SM = 3 (deduped)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mquery_semantic_memory\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mRetrieved 0 SM results\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.758\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_semantic\u001b[0m:\u001b[36m162\u001b[0m - \u001b[34m\u001b[1mRetrieved 0 SM results for intent=compliance_query, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.758\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_merge_results\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mMerged results: 5 EM + 0 SM = 3 (deduped)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mquery_episodic_memory\u001b[0m:\u001b[36m128\u001b[0m - \u001b[1mRetrieved 5 EM results\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mrerank_results\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mReranking 0 EM + 0 SM results\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:50.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36mrecall\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mMemory recall: query=What Incoterms are best for shipping to Africa?, intent=compliance_query, session=demo-session-001, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:51.306\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_episodic\u001b[0m:\u001b[36m110\u001b[0m - \u001b[34m\u001b[1mRetrieved 5 EM results for session demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:51.498\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_query_semantic\u001b[0m:\u001b[36m162\u001b[0m - \u001b[34m\u001b[1mRetrieved 0 SM results for intent=compliance_query, entities=1\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:51.498\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.memory_service.service\u001b[0m:\u001b[36m_merge_results\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mMerged results: 5 EM + 0 SM = 3 (deduped)\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:51.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mrerank_results\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mReranked to 3 results\u001b[0m\n",
      "\u001b[32m2025-10-19 21:49:51.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mGenerating response with memory context\u001b[0m\n",
      "\u001b[32m2025-10-19 21:50:11.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mGenerated response with 4 citations\u001b[0m\n",
      "\u001b[32m2025-10-19 21:50:11.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.graph\u001b[0m:\u001b[36mupdate_working_memory\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mUpdating working memory for session: demo-session-001\u001b[0m\n",
      "\u001b[32m2025-10-19 21:50:11.066\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36macc_llamaindex.application.chat_service.session_manager\u001b[0m:\u001b[36madd_turn\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mAdded turn 3 to session demo-session-001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Memory Graph Execution Complete ===\n",
      "\n",
      "User Query: What Incoterms are best for shipping to Africa?\n",
      "\n",
      "Intent: compliance_query (confidence: 0.62)\n",
      "Entities: ['Incoterms']\n",
      "\n",
      "Working Memory: 2 turns\n",
      "EM Results: 0\n",
      "SM Results: 0\n",
      "Reranked Context: 3\n",
      "\n",
      "Response:\n",
      "Based on your context (you prefer FOB, you’re exporting textiles to Nigeria, and you’re working with a Lagos supplier), here are the Incoterms that tend to work best for shipping to Africa, with notes on when to use them:\n",
      "\n",
      "- FOB (Free On Board) — strongest default for sea shipments from Lagos\n",
      "  - Your Lagos supplier handles export clearance and loads the goods onto the ship.\n",
      "  - Risk transfers to you when the goods pass the ship’s rail; you then arrange ocean freight and insurance from the port onward.\n",
      "  - This matches your stated preference for FOB [EM-1] and fits your Lagos supplier setup [EM-3].\n",
      "\n",
      "- CFR (Cost and Freight) — if you want the seller to pay freight to the destination port, but you handle insurance\n",
      "  - Seller covers cost and freight to the destination port.\n",
      "  - You arrange insurance yourself (not included in CFR).\n",
      "  - Useful if you want predictability on freight costs but still manage insurance decisions yourself.\n",
      "\n",
      "- CIF (Cost, Insurance and Freight) — if you want insurance included as part of the package\n",
      "  - Seller covers cost, freight, and minimum insurance to the destination port.\n",
      "  - Simplifies risk management for you since insurance is included, but verify coverage levels.\n",
      "\n",
      "- DAP (Delivered at Place) or DDP (Delivered Duty Paid) — if you want delivery closer to your facility and/or import duties handled\n",
      "  - DAP: Seller delivers ready for import at a named destination; you handle import duties/taxes.\n",
      "  - DDP: Seller handles duties and delivers to your door; higher seller risk and complexity.\n",
      "  - These are options if you want less hassle on the import side, but confirm they fit your labelling, duties, and local regulations.\n",
      "\n",
      "- For air shipments or multi-modal conveyance (instead of sea)\n",
      "  - Use FCA (Free Carrier) at origin, or CPT/CIP if you want the seller to cover some transport legs or to include insurance.\n",
      "\n",
      "Quick tips\n",
      "- Since you’re in Lagos and working with a Lagos supplier, FOB Lagos is a solid default for sea freight [EM-1][EM-3].\n",
      "- Choose CIF if you want insurance included by the seller; CFR if you want to control insurance yourself.\n",
      "- If your shipments are multi-modal or you want door delivery in Africa, consider DAP or DDP, but be aware of the additional complexity and costs.\n",
      "- Always specify the exact named port of shipment and the destination, and clearly state which party handles export/import clearance, insurance, and duties in your contract.\n",
      "\n",
      "Would you like me to tailor this to a specific route (e.g., Lagos to a particular African port) and a preferred mode (sea vs air) so I can suggest a concrete Incoterm and a short check-list for your contract?\n",
      "\n",
      "Citations: 4\n",
      "Should Distill: False\n"
     ]
    }
   ],
   "source": [
    "# Get the compiled memory graph\n",
    "memory_graph = get_memory_graph()\n",
    "\n",
    "# Create initial state\n",
    "initial_state = MemoryState(\n",
    "    user_query=\"What Incoterms are best for shipping to Africa?\",\n",
    "    session_id=session_id,\n",
    "    wm_context=[],\n",
    "    intent=\"\",\n",
    "    confidence=0.0,\n",
    "    entities=[],\n",
    "    em_results=[],\n",
    "    sm_results=[],\n",
    "    reranked_context=[],\n",
    "    response=\"\",\n",
    "    citations=[],\n",
    "    should_distill=False,\n",
    "    retrieval_ms=0.0,\n",
    "    generation_ms=0.0\n",
    ")\n",
    "\n",
    "# Execute the graph\n",
    "print(\"Executing memory graph...\\n\")\n",
    "final_state = memory_graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n=== Memory Graph Execution Complete ===\\n\")\n",
    "print(f\"User Query: {final_state['user_query']}\")\n",
    "print(f\"\\nIntent: {final_state['intent']} (confidence: {final_state['confidence']:.2f})\")\n",
    "print(f\"Entities: {[e.get('text', '') for e in final_state['entities']]}\")\n",
    "print(f\"\\nWorking Memory: {len(final_state['wm_context'])} turns\")\n",
    "print(f\"EM Results: {len(final_state['em_results'])}\")\n",
    "print(f\"SM Results: {len(final_state['sm_results'])}\")\n",
    "print(f\"Reranked Context: {len(final_state['reranked_context'])}\")\n",
    "print(f\"\\nResponse:\\n{final_state['response']}\")\n",
    "print(f\"\\nCitations: {len(final_state['citations'])}\")\n",
    "print(f\"Should Distill: {final_state['should_distill']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Salience Tracking and Distillation\n",
    "\n",
    "Salience tracking determines which memories are most important.\n",
    "\n",
    "### Pattern 1: Track Citation Salience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'llm_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     category: \u001b[38;5;28mstr\u001b[39m = Field(description=\u001b[33m\"\u001b[39m\u001b[33mDocument category (e.g., technical, guide, reference)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# reset llm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllm_provider\u001b[49m=\u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m reset_llm()\n\u001b[32m     15\u001b[39m llm = get_llm()\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'llm_provider'"
     ]
    }
   ],
   "source": [
    "# Simulate tracking citations\n",
    "cited_facts = [\n",
    "    {\"text\": \"User prefers FOB Incoterms\", \"id\": \"fact-1\"},\n",
    "    {\"text\": \"User is exporting textiles\", \"id\": \"fact-2\"}\n",
    "]\n",
    "\n",
    "salience_tracker.track_citations(cited_facts)\n",
    "print(\"Tracked citations for salience scoring\")\n",
    "\n",
    "# Get salience scores\n",
    "for fact in cited_facts:\n",
    "    score = salience_tracker.get_salience_score(fact['id'])\n",
    "    print(f\"  {fact['text']}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Conversation Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent handled potential errors gracefully\n"
     ]
    }
   ],
   "source": [
    "# Get recent turns to distill\n",
    "turns_to_distill = session_manager.get_recent_turns(session_id, n=2)\n",
    "\n",
    "print(f\"Distilling {len(turns_to_distill)} conversation turns...\\n\")\n",
    "\n",
    "# Distill into facts\n",
    "distill_result = conversation_summarizer.distill(\n",
    "    session_id=session_id,\n",
    "    turns=turns_to_distill\n",
    ")\n",
    "\n",
    "print(f\"Distillation Result:\")\n",
    "print(f\"  Success: {distill_result.get('success', False)}\")\n",
    "print(f\"  Facts Created: {distill_result.get('facts_created', 0)}\")\n",
    "print(f\"\\nExtracted Facts:\")\n",
    "for fact in distill_result.get('facts', []):\n",
    "    print(f\"  - {fact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. End-to-End Scenario\n",
    "\n",
    "Complete workflow demonstrating the full memory system.\n",
    "\n",
    "### Scenario: Multi-Turn Conversation with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new session for this scenario\n",
    "scenario_session_id = \"scenario-001\"\n",
    "\n",
    "print(\"Simulating Multi-Turn Conversation:\\n\")\n",
    "\n",
    "# Turn 1\n",
    "state1 = MemoryState(\n",
    "    user_query=\"What are Incoterms?\",\n",
    "    session_id=scenario_session_id,\n",
    "    wm_context=[], intent=\"\", confidence=0.0, entities=[],\n",
    "    em_results=[], sm_results=[], reranked_context=[],\n",
    "    response=\"\", citations=[], should_distill=False,\n",
    "    retrieval_ms=0.0, generation_ms=0.0\n",
    ")\n",
    "result1 = memory_graph.invoke(state1)\n",
    "print(f\"Turn 1:\")\n",
    "print(f\"  User: {result1['user_query']}\")\n",
    "print(f\"  Intent: {result1['intent']}\")\n",
    "print(f\"  Response: {result1['response'][:100]}...\\n\")\n",
    "\n",
    "# Turn 2\n",
    "state2 = MemoryState(\n",
    "    user_query=\"Which one is best for sea freight?\",\n",
    "    session_id=scenario_session_id,\n",
    "    wm_context=[], intent=\"\", confidence=0.0, entities=[],\n",
    "    em_results=[], sm_results=[], reranked_context=[],\n",
    "    response=\"\", citations=[], should_distill=False,\n",
    "    retrieval_ms=0.0, generation_ms=0.0\n",
    ")\n",
    "result2 = memory_graph.invoke(state2)\n",
    "print(f\"Turn 2:\")\n",
    "print(f\"  User: {result2['user_query']}\")\n",
    "print(f\"  WM Context: {len(result2['wm_context'])} previous turns\")\n",
    "print(f\"  Response: {result2['response'][:100]}...\\n\")\n",
    "\n",
    "# Turn 3 - tests memory recall\n",
    "state3 = MemoryState(\n",
    "    user_query=\"What did we discuss earlier?\",\n",
    "    session_id=scenario_session_id,\n",
    "    wm_context=[], intent=\"\", confidence=0.0, entities=[],\n",
    "    em_results=[], sm_results=[], reranked_context=[],\n",
    "    response=\"\", citations=[], should_distill=False,\n",
    "    retrieval_ms=0.0, generation_ms=0.0\n",
    ")\n",
    "result3 = memory_graph.invoke(state3)\n",
    "print(f\"Turn 3:\")\n",
    "print(f\"  User: {result3['user_query']}\")\n",
    "print(f\"  WM Context: {len(result3['wm_context'])} previous turns\")\n",
    "print(f\"  EM Results: {len(result3['em_results'])}\")\n",
    "print(f\"  Response: {result3['response'][:150]}...\\n\")\n",
    "\n",
    "print(\"\\n=== Scenario Complete ===\")\n",
    "session_stats = session_manager.get_session(scenario_session_id)\n",
    "print(f\"Total turns in session: {session_stats['turn_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Working Memory**: In-memory session management with LRU eviction and TTL cleanup\n",
    "2. **Intent Classification**: LLM-based routing for different query types\n",
    "3. **Entity Extraction**: Identifying key entities in user queries\n",
    "4. **Episodic Memory**: Session-specific facts from conversation distillation\n",
    "5. **Semantic Memory**: Long-term document knowledge retrieval\n",
    "6. **Memory Fusion**: Combining EM + SM with intelligent reranking\n",
    "7. **LangGraph Flow**: State machine orchestration of all memory tiers\n",
    "8. **Salience Tracking**: Importance scoring for memory items\n",
    "9. **Distillation**: Automatic fact extraction from conversations\n",
    "10. **End-to-End**: Full multi-turn conversations with memory\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **WM** provides fast access to recent context\n",
    "- **EM** stores personalized session facts\n",
    "- **SM** retrieves relevant document knowledge\n",
    "- **LangGraph** coordinates the flow between memory tiers\n",
    "- **Salience** ensures important facts are retained\n",
    "- **Distillation** automatically extracts conversation facts\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different distillation frequencies\n",
    "- Test salience-based memory promotion\n",
    "- Implement custom reranking strategies\n",
    "- Add memory decay mechanisms\n",
    "- Explore cross-session memory sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
